{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "every-beaver",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ordered-puppy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 127)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>AreaName</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Vax_White</th>\n",
       "      <th>Vax_Black</th>\n",
       "      <th>VaxNumb_White</th>\n",
       "      <th>VaxNumb_Black</th>\n",
       "      <th>Total_Whole</th>\n",
       "      <th>Total_White</th>\n",
       "      <th>...</th>\n",
       "      <th>HighSchool_Disparity</th>\n",
       "      <th>Bachelor_Disparity</th>\n",
       "      <th>IT_Disparity</th>\n",
       "      <th>CnoI_Disparity</th>\n",
       "      <th>noC_Disparity</th>\n",
       "      <th>Above75_Disparity</th>\n",
       "      <th>Unemployment_Disparity</th>\n",
       "      <th>MeanIncome_Disparity</th>\n",
       "      <th>MedianIncome_Disparity</th>\n",
       "      <th>FluVax_Disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>California</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>Alameda, California</td>\n",
       "      <td>6001</td>\n",
       "      <td>0.272713</td>\n",
       "      <td>0.270879</td>\n",
       "      <td>224604.927990</td>\n",
       "      <td>49941.375150</td>\n",
       "      <td>1671329</td>\n",
       "      <td>823593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>24218.0</td>\n",
       "      <td>56757.0</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>California</td>\n",
       "      <td>Amador</td>\n",
       "      <td>Amador, California</td>\n",
       "      <td>6005</td>\n",
       "      <td>0.324251</td>\n",
       "      <td>0.075991</td>\n",
       "      <td>11554.998532</td>\n",
       "      <td>81.005884</td>\n",
       "      <td>39752</td>\n",
       "      <td>35636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.057</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.102773</td>\n",
       "      <td>0.070</td>\n",
       "      <td>32510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California</td>\n",
       "      <td>Butte</td>\n",
       "      <td>Butte, California</td>\n",
       "      <td>6007</td>\n",
       "      <td>0.228574</td>\n",
       "      <td>0.141172</td>\n",
       "      <td>42912.995913</td>\n",
       "      <td>586.991907</td>\n",
       "      <td>219186</td>\n",
       "      <td>187742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.042232</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>13412.0</td>\n",
       "      <td>23524.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California</td>\n",
       "      <td>Calaveras</td>\n",
       "      <td>Calaveras, California</td>\n",
       "      <td>6009</td>\n",
       "      <td>0.241905</td>\n",
       "      <td>0.168666</td>\n",
       "      <td>10100.002995</td>\n",
       "      <td>83.995770</td>\n",
       "      <td>45905</td>\n",
       "      <td>41752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.037466</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>15259.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>Colusa</td>\n",
       "      <td>Colusa, California</td>\n",
       "      <td>6011</td>\n",
       "      <td>0.102547</td>\n",
       "      <td>0.117030</td>\n",
       "      <td>2013.000112</td>\n",
       "      <td>33.002424</td>\n",
       "      <td>21547</td>\n",
       "      <td>19630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.006429</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>11741.0</td>\n",
       "      <td>40316.0</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Williamsburg city</td>\n",
       "      <td>Williamsburg city, Virginia</td>\n",
       "      <td>51830</td>\n",
       "      <td>0.225461</td>\n",
       "      <td>0.156002</td>\n",
       "      <td>2483.000000</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>14954</td>\n",
       "      <td>11013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.192</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.039609</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>11783.0</td>\n",
       "      <td>9393.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Winchester city</td>\n",
       "      <td>Winchester city, Virginia</td>\n",
       "      <td>51840</td>\n",
       "      <td>0.124486</td>\n",
       "      <td>0.101134</td>\n",
       "      <td>2846.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>28078</td>\n",
       "      <td>22862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.036097</td>\n",
       "      <td>0.013</td>\n",
       "      <td>6004.0</td>\n",
       "      <td>3525.0</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Wise</td>\n",
       "      <td>Wise, Virginia</td>\n",
       "      <td>51195</td>\n",
       "      <td>0.229298</td>\n",
       "      <td>0.079093</td>\n",
       "      <td>7925.000000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>37383</td>\n",
       "      <td>34562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.062452</td>\n",
       "      <td>0.051</td>\n",
       "      <td>7050.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>Wythe</td>\n",
       "      <td>Wythe, Virginia</td>\n",
       "      <td>51197</td>\n",
       "      <td>0.155766</td>\n",
       "      <td>0.131301</td>\n",
       "      <td>4225.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>28684</td>\n",
       "      <td>27124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>6620.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>York</td>\n",
       "      <td>York, Virginia</td>\n",
       "      <td>51199</td>\n",
       "      <td>0.235383</td>\n",
       "      <td>0.189790</td>\n",
       "      <td>12114.000000</td>\n",
       "      <td>1792.000000</td>\n",
       "      <td>68280</td>\n",
       "      <td>51465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.012913</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>7239.0</td>\n",
       "      <td>24802.0</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           State             County                     AreaName   FIPS  \\\n",
       "0     California            Alameda          Alameda, California   6001   \n",
       "1     California             Amador           Amador, California   6005   \n",
       "2     California              Butte            Butte, California   6007   \n",
       "3     California          Calaveras        Calaveras, California   6009   \n",
       "4     California             Colusa           Colusa, California   6011   \n",
       "...          ...                ...                          ...    ...   \n",
       "1288    Virginia  Williamsburg city  Williamsburg city, Virginia  51830   \n",
       "1289    Virginia    Winchester city    Winchester city, Virginia  51840   \n",
       "1290    Virginia               Wise               Wise, Virginia  51195   \n",
       "1291    Virginia              Wythe              Wythe, Virginia  51197   \n",
       "1292    Virginia               York               York, Virginia  51199   \n",
       "\n",
       "      Vax_White  Vax_Black  VaxNumb_White  VaxNumb_Black  Total_Whole  \\\n",
       "0      0.272713   0.270879  224604.927990   49941.375150      1671329   \n",
       "1      0.324251   0.075991   11554.998532      81.005884        39752   \n",
       "2      0.228574   0.141172   42912.995913     586.991907       219186   \n",
       "3      0.241905   0.168666   10100.002995      83.995770        45905   \n",
       "4      0.102547   0.117030    2013.000112      33.002424        21547   \n",
       "...         ...        ...            ...            ...          ...   \n",
       "1288   0.225461   0.156002    2483.000000     373.000000        14954   \n",
       "1289   0.124486   0.101134    2846.000000     321.000000        28078   \n",
       "1290   0.229298   0.079093    7925.000000     171.000000        37383   \n",
       "1291   0.155766   0.131301    4225.000000     112.000000        28684   \n",
       "1292   0.235383   0.189790   12114.000000    1792.000000        68280   \n",
       "\n",
       "      Total_White  ...  HighSchool_Disparity  Bachelor_Disparity  \\\n",
       "0          823593  ...                 0.015               0.232   \n",
       "1           35636  ...                 0.263               0.182   \n",
       "2          187742  ...                -0.009               0.068   \n",
       "3           41752  ...                 0.238               0.065   \n",
       "4           19630  ...                -0.030               0.064   \n",
       "...           ...  ...                   ...                 ...   \n",
       "1288        11013  ...                 0.154               0.498   \n",
       "1289        22862  ...                 0.017               0.214   \n",
       "1290        34562  ...                 0.132               0.117   \n",
       "1291        27124  ...                 0.002               0.107   \n",
       "1292        51465  ...                 0.065               0.135   \n",
       "\n",
       "      IT_Disparity  CnoI_Disparity  noC_Disparity  Above75_Disparity  \\\n",
       "0            0.096          -0.053         -0.044           0.004083   \n",
       "1            0.344           0.057         -0.408           0.102773   \n",
       "2            0.064          -0.087          0.021           0.042232   \n",
       "3           -0.138           0.061          0.065           0.037466   \n",
       "4           -0.012          -0.036          0.045          -0.006429   \n",
       "...            ...             ...            ...                ...   \n",
       "1288         0.226          -0.192         -0.037           0.039609   \n",
       "1289         0.117          -0.028         -0.090           0.036097   \n",
       "1290        -0.260           0.166          0.088           0.062452   \n",
       "1291         0.259          -0.123         -0.142           0.007275   \n",
       "1292         0.011          -0.001         -0.009           0.012913   \n",
       "\n",
       "      Unemployment_Disparity  MeanIncome_Disparity  MedianIncome_Disparity  \\\n",
       "0                     -0.048               24218.0                 56757.0   \n",
       "1                      0.070               32510.0                     NaN   \n",
       "2                     -0.123               13412.0                 23524.0   \n",
       "3                     -0.396               15259.0                     NaN   \n",
       "4                     -0.036               11741.0                 40316.0   \n",
       "...                      ...                   ...                     ...   \n",
       "1288                  -0.065               11783.0                  9393.0   \n",
       "1289                   0.013                6004.0                  3525.0   \n",
       "1290                   0.051                7050.0                     NaN   \n",
       "1291                  -0.007                6620.0                     NaN   \n",
       "1292                  -0.009                7239.0                 24802.0   \n",
       "\n",
       "      FluVax_Disparity  \n",
       "0                 0.24  \n",
       "1                 0.10  \n",
       "2                 0.13  \n",
       "3                 0.08  \n",
       "4                 0.13  \n",
       "...                ...  \n",
       "1288              0.20  \n",
       "1289              0.16  \n",
       "1290              0.04  \n",
       "1291              0.20  \n",
       "1292              0.17  \n",
       "\n",
       "[1199 rows x 127 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# T2 = pd.read_csv('StataReg/CountyVaccineMarch27.csv')\n",
    "# T2 = pd.read_csv('StataReg/CountyVaccineApril07.csv')\n",
    "T2 = pd.read_csv('StataReg/CountyVaccineApril19.csv')\n",
    "# first processing\n",
    "T2 = T2[-T2['Vax_Disparity'].isna()]\n",
    "T2 = T2[T2['Vax_White'] < 1]\n",
    "T2 = T2[T2['Vax_Black'] < 1]\n",
    "print(T2.shape)\n",
    "# print(T2.shape)\n",
    "\n",
    "T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "anonymous-torture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "California         54\n",
       "Illinois          102\n",
       "Indiana            89\n",
       "Maine              16\n",
       "New Jersey         21\n",
       "New York           62\n",
       "North Carolina     43\n",
       "Ohio               88\n",
       "Oregon             23\n",
       "Pennsylvania       60\n",
       "South Carolina     46\n",
       "Tennessee          90\n",
       "Texas             245\n",
       "Virginia          133\n",
       "West Virginia      55\n",
       "Wisconsin          72\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T2['State'].value_counts().sort_index()#.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-addiction",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "burning-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MedianIncome  MedianIncome_Disparity\n",
      "count    1199.000000              845.000000\n",
      "mean    55893.006672            17913.034320\n",
      "std     14984.295779            18555.546814\n",
      "min     25098.000000          -190594.000000\n",
      "25%     46916.000000            11036.000000\n",
      "50%     52982.000000            19688.000000\n",
      "75%     60980.500000            27892.000000\n",
      "max    142299.000000           106200.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighSchool_Rate</th>\n",
       "      <th>HighSchool_Disparity</th>\n",
       "      <th>FacNumRate</th>\n",
       "      <th>CaseRate</th>\n",
       "      <th>IT_Rate</th>\n",
       "      <th>IT_Disparity</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>republican_rate</th>\n",
       "      <th>Segregation</th>\n",
       "      <th>racial_weighted_bias</th>\n",
       "      <th>hesitancy</th>\n",
       "      <th>Black_Prop</th>\n",
       "      <th>FluVax_Rate</th>\n",
       "      <th>FluVax_Disparity</th>\n",
       "      <th>Above75_Rate</th>\n",
       "      <th>Above75_Disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1186.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1162.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>924.000000</td>\n",
       "      <td>1197.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.602825</td>\n",
       "      <td>0.053352</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.093301</td>\n",
       "      <td>0.812683</td>\n",
       "      <td>0.055262</td>\n",
       "      <td>0.933815</td>\n",
       "      <td>0.633334</td>\n",
       "      <td>0.463605</td>\n",
       "      <td>0.397422</td>\n",
       "      <td>0.180442</td>\n",
       "      <td>0.085660</td>\n",
       "      <td>0.452796</td>\n",
       "      <td>0.146880</td>\n",
       "      <td>0.081656</td>\n",
       "      <td>0.044046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.137903</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.027591</td>\n",
       "      <td>0.072152</td>\n",
       "      <td>0.175349</td>\n",
       "      <td>0.043281</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.166147</td>\n",
       "      <td>0.017615</td>\n",
       "      <td>0.035371</td>\n",
       "      <td>0.116537</td>\n",
       "      <td>0.090696</td>\n",
       "      <td>0.081638</td>\n",
       "      <td>0.020189</td>\n",
       "      <td>0.029623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.294580</td>\n",
       "      <td>-0.413000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018406</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>-0.495000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.112492</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.311562</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.220000</td>\n",
       "      <td>0.032670</td>\n",
       "      <td>-0.073795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.577624</td>\n",
       "      <td>-0.022000</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.075749</td>\n",
       "      <td>0.771000</td>\n",
       "      <td>-0.044000</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>0.531834</td>\n",
       "      <td>0.345283</td>\n",
       "      <td>0.390263</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.068744</td>\n",
       "      <td>0.024901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.614722</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.093884</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.941000</td>\n",
       "      <td>0.663528</td>\n",
       "      <td>0.475750</td>\n",
       "      <td>0.399803</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.037990</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.081012</td>\n",
       "      <td>0.042159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.641161</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.110162</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.756338</td>\n",
       "      <td>0.578347</td>\n",
       "      <td>0.406107</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.103657</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.093258</td>\n",
       "      <td>0.062781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.763248</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.241306</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954327</td>\n",
       "      <td>0.862028</td>\n",
       "      <td>0.444530</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.769731</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.178534</td>\n",
       "      <td>0.162831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HighSchool_Rate  HighSchool_Disparity   FacNumRate     CaseRate  \\\n",
       "count      1199.000000           1186.000000  1199.000000  1199.000000   \n",
       "mean          0.602825              0.053352     0.000251     0.093301   \n",
       "std           0.062745              0.137903     0.000161     0.027591   \n",
       "min           0.294580             -0.413000     0.000000     0.018406   \n",
       "25%           0.577624             -0.022000     0.000166     0.075749   \n",
       "50%           0.614722              0.042000     0.000214     0.093884   \n",
       "75%           0.641161              0.110000     0.000289     0.110162   \n",
       "max           0.763248              0.883000     0.001590     0.241306   \n",
       "\n",
       "           IT_Rate  IT_Disparity      vehicle  republican_rate  Segregation  \\\n",
       "count  1199.000000   1162.000000  1199.000000      1199.000000   924.000000   \n",
       "mean      0.812683      0.055262     0.933815         0.633334     0.463605   \n",
       "std       0.072152      0.175349     0.043281         0.162193     0.166147   \n",
       "min       0.509000     -0.495000     0.230000         0.112492     0.000408   \n",
       "25%       0.771000     -0.044000     0.922000         0.531834     0.345283   \n",
       "50%       0.822000      0.054000     0.941000         0.663528     0.475750   \n",
       "75%       0.862000      0.133000     0.954000         0.756338     0.578347   \n",
       "max       0.970000      0.824000     1.000000         0.954327     0.862028   \n",
       "\n",
       "       racial_weighted_bias    hesitancy   Black_Prop  FluVax_Rate  \\\n",
       "count           1197.000000  1199.000000  1199.000000  1198.000000   \n",
       "mean               0.397422     0.180442     0.085660     0.452796   \n",
       "std                0.017615     0.035371     0.116537     0.090696   \n",
       "min                0.311562     0.070000     0.002945     0.100000   \n",
       "25%                0.390263     0.160000     0.012487     0.400000   \n",
       "50%                0.399803     0.180000     0.037990     0.470000   \n",
       "75%                0.406107     0.200000     0.103657     0.520000   \n",
       "max                0.444530     0.270000     0.769731     0.650000   \n",
       "\n",
       "       FluVax_Disparity  Above75_Rate  Above75_Disparity  \n",
       "count        968.000000   1199.000000        1199.000000  \n",
       "mean           0.146880      0.081656           0.044046  \n",
       "std            0.081638      0.020189           0.029623  \n",
       "min           -0.220000      0.032670          -0.073795  \n",
       "25%            0.100000      0.068744           0.024901  \n",
       "50%            0.150000      0.081012           0.042159  \n",
       "75%            0.190000      0.093258           0.062781  \n",
       "max            0.510000      0.178534           0.162831  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T2['FacNum'] = T2[['FQHC', 'HOPD', 'PHMCY', 'RUHC'] ].sum(axis = 1)\n",
    "T2['vehicle'] = 1- T2['EP_NOVEH']\n",
    "\n",
    "T2['Vax_DisparityY'] = T2['Vax_Disparity']*100\n",
    "T2['FluVax_DisparityY'] = T2['FluVax_Disparity']*100\n",
    "\n",
    "T2['logFacNum' ] = np.log(T2['FacNum' ] + 1)\n",
    "T2['logcases' ] = np.log(T2['cases' ] + 1)\n",
    "\n",
    "T2['CaseRate' ] = T2['cases' ]/T2['Total_Whole']\n",
    "T2['FacNumRate' ] = T2['FacNum' ]/T2['Total_Whole'] \n",
    "T2['Black_Prop' ] = T2['Total_Black' ]/T2['Total_Whole']\n",
    "\n",
    "T2['Segregation'] = T2['Segregation'] / 100\n",
    "\n",
    "\n",
    "money_cols = ['MedianIncome', 'MedianIncome_Disparity',]\n",
    "rate_cols = ['HighSchool_Rate','HighSchool_Disparity','FacNumRate',\n",
    "'CaseRate', 'IT_Rate','IT_Disparity','vehicle','republican_rate','Segregation','racial_weighted_bias','hesitancy','Black_Prop',\n",
    "             'FluVax_Rate', 'FluVax_Disparity', 'Above75_Rate', 'Above75_Disparity']\n",
    "\n",
    "print(T2[money_cols].describe())\n",
    "T2[rate_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "quiet-claim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MedianIncome  MedianIncome_Disparity\n",
      "count   1199.000000              845.000000\n",
      "mean      55.893007               17.913034\n",
      "std       14.984296               18.555547\n",
      "min       25.098000             -190.594000\n",
      "25%       46.916000               11.036000\n",
      "50%       52.982000               19.688000\n",
      "75%       60.980500               27.892000\n",
      "max      142.299000              106.200000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighSchool_Rate</th>\n",
       "      <th>HighSchool_Disparity</th>\n",
       "      <th>FacNumRate</th>\n",
       "      <th>CaseRate</th>\n",
       "      <th>IT_Rate</th>\n",
       "      <th>IT_Disparity</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>republican_rate</th>\n",
       "      <th>Segregation</th>\n",
       "      <th>racial_weighted_bias</th>\n",
       "      <th>hesitancy</th>\n",
       "      <th>Black_Prop</th>\n",
       "      <th>FluVax_Rate</th>\n",
       "      <th>FluVax_Disparity</th>\n",
       "      <th>Above75_Rate</th>\n",
       "      <th>Above75_Disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1186.00000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1162.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>924.000000</td>\n",
       "      <td>1197.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1198.000000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.282484</td>\n",
       "      <td>5.33516</td>\n",
       "      <td>0.025064</td>\n",
       "      <td>9.330142</td>\n",
       "      <td>81.268307</td>\n",
       "      <td>5.526248</td>\n",
       "      <td>93.381485</td>\n",
       "      <td>63.333369</td>\n",
       "      <td>46.360491</td>\n",
       "      <td>39.742156</td>\n",
       "      <td>18.044204</td>\n",
       "      <td>8.565969</td>\n",
       "      <td>45.279633</td>\n",
       "      <td>14.688017</td>\n",
       "      <td>8.165563</td>\n",
       "      <td>4.404576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.274502</td>\n",
       "      <td>13.79028</td>\n",
       "      <td>0.016097</td>\n",
       "      <td>2.759132</td>\n",
       "      <td>7.215182</td>\n",
       "      <td>17.534850</td>\n",
       "      <td>4.328084</td>\n",
       "      <td>16.219322</td>\n",
       "      <td>16.614695</td>\n",
       "      <td>1.761480</td>\n",
       "      <td>3.537146</td>\n",
       "      <td>11.653661</td>\n",
       "      <td>9.069550</td>\n",
       "      <td>8.163770</td>\n",
       "      <td>2.018857</td>\n",
       "      <td>2.962300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.457999</td>\n",
       "      <td>-41.30000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.840614</td>\n",
       "      <td>50.900000</td>\n",
       "      <td>-49.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>11.249201</td>\n",
       "      <td>0.040823</td>\n",
       "      <td>31.156179</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.294468</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-22.000000</td>\n",
       "      <td>3.266964</td>\n",
       "      <td>-7.379458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.762441</td>\n",
       "      <td>-2.20000</td>\n",
       "      <td>0.016640</td>\n",
       "      <td>7.574911</td>\n",
       "      <td>77.100000</td>\n",
       "      <td>-4.400000</td>\n",
       "      <td>92.200000</td>\n",
       "      <td>53.183369</td>\n",
       "      <td>34.528252</td>\n",
       "      <td>39.026276</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.248729</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.874368</td>\n",
       "      <td>2.490147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>61.472175</td>\n",
       "      <td>4.20000</td>\n",
       "      <td>0.021428</td>\n",
       "      <td>9.388433</td>\n",
       "      <td>82.200000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>94.100000</td>\n",
       "      <td>66.352750</td>\n",
       "      <td>47.574962</td>\n",
       "      <td>39.980284</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>3.798996</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>8.101170</td>\n",
       "      <td>4.215893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64.116122</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>0.028882</td>\n",
       "      <td>11.016191</td>\n",
       "      <td>86.200000</td>\n",
       "      <td>13.300000</td>\n",
       "      <td>95.400000</td>\n",
       "      <td>75.633783</td>\n",
       "      <td>57.834746</td>\n",
       "      <td>40.610726</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.365744</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.325782</td>\n",
       "      <td>6.278127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>76.324771</td>\n",
       "      <td>88.30000</td>\n",
       "      <td>0.158983</td>\n",
       "      <td>24.130559</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>82.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>95.432692</td>\n",
       "      <td>86.202837</td>\n",
       "      <td>44.452995</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>76.973139</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>17.853438</td>\n",
       "      <td>16.283116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HighSchool_Rate  HighSchool_Disparity   FacNumRate     CaseRate  \\\n",
       "count      1199.000000            1186.00000  1199.000000  1199.000000   \n",
       "mean         60.282484               5.33516     0.025064     9.330142   \n",
       "std           6.274502              13.79028     0.016097     2.759132   \n",
       "min          29.457999             -41.30000     0.000000     1.840614   \n",
       "25%          57.762441              -2.20000     0.016640     7.574911   \n",
       "50%          61.472175               4.20000     0.021428     9.388433   \n",
       "75%          64.116122              11.00000     0.028882    11.016191   \n",
       "max          76.324771              88.30000     0.158983    24.130559   \n",
       "\n",
       "           IT_Rate  IT_Disparity      vehicle  republican_rate  Segregation  \\\n",
       "count  1199.000000   1162.000000  1199.000000      1199.000000   924.000000   \n",
       "mean     81.268307      5.526248    93.381485        63.333369    46.360491   \n",
       "std       7.215182     17.534850     4.328084        16.219322    16.614695   \n",
       "min      50.900000    -49.500000    23.000000        11.249201     0.040823   \n",
       "25%      77.100000     -4.400000    92.200000        53.183369    34.528252   \n",
       "50%      82.200000      5.400000    94.100000        66.352750    47.574962   \n",
       "75%      86.200000     13.300000    95.400000        75.633783    57.834746   \n",
       "max      97.000000     82.400000   100.000000        95.432692    86.202837   \n",
       "\n",
       "       racial_weighted_bias    hesitancy   Black_Prop  FluVax_Rate  \\\n",
       "count           1197.000000  1199.000000  1199.000000  1198.000000   \n",
       "mean              39.742156    18.044204     8.565969    45.279633   \n",
       "std                1.761480     3.537146    11.653661     9.069550   \n",
       "min               31.156179     7.000000     0.294468    10.000000   \n",
       "25%               39.026276    16.000000     1.248729    40.000000   \n",
       "50%               39.980284    18.000000     3.798996    47.000000   \n",
       "75%               40.610726    20.000000    10.365744    52.000000   \n",
       "max               44.452995    27.000000    76.973139    65.000000   \n",
       "\n",
       "       FluVax_Disparity  Above75_Rate  Above75_Disparity  \n",
       "count        968.000000   1199.000000        1199.000000  \n",
       "mean          14.688017      8.165563           4.404576  \n",
       "std            8.163770      2.018857           2.962300  \n",
       "min          -22.000000      3.266964          -7.379458  \n",
       "25%           10.000000      6.874368           2.490147  \n",
       "50%           15.000000      8.101170           4.215893  \n",
       "75%           19.000000      9.325782           6.278127  \n",
       "max           51.000000     17.853438          16.283116  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in money_cols:\n",
    "    T2[i] = T2[i] / 1000\n",
    "\n",
    "for i in rate_cols:\n",
    "    T2[i] = T2[i] * 100\n",
    "\n",
    "print(T2[money_cols].describe())\n",
    "T2[rate_cols].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-phase",
   "metadata": {},
   "source": [
    "# Make Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "operating-nebraska",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate Path: StataReg/RegResult/2021-04-22_16-31-18\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "folder = str(datetime.now()).split('.')[0].replace(':', '-').replace(' ', '_')\n",
    "Result = 'StataReg/RegResult'\n",
    "path = os.path.join(Result, folder)\n",
    "print('Generate Path:', path)\n",
    "os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-ghost",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mineral-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefix cols: ['State', 'County']\n",
      "addition cols: ['log_Total_Whole', 'BlackWhiteRatio', 'Total_Black', 'org_Total_Whole', 'IT_Disparity']\n",
      "From: (1199, 10)\n",
      "Dropping Nan in Independent Variables\n",
      "To  : (1157, 10)\n",
      "(913, 10)\n",
      "Dropping Small Black Population\n",
      "To  : (913, 10)\n",
      "StataReg/RegResult/2021-04-22_16-31-18/DataVarDict.csv\n",
      "StataReg/RegResult/2021-04-22_16-31-18/Data.dta\n",
      "StataReg/RegResult/2021-04-22_16-31-18/DataVarDictNorm.csv\n",
      "StataReg/RegResult/2021-04-22_16-31-18/DataNorm.dta\n"
     ]
    }
   ],
   "source": [
    "def get_stata(T2, cols, path):\n",
    "    T2['log_Total_Whole'] = np.log(T2['Total_Whole'])\n",
    "    T2['org_Total_Whole'] = T2['Total_Whole'] + 0\n",
    "    T2['BlackWhiteRatio'] = T2['Total_Black']/T2['Total_White']\n",
    "    \n",
    "    prefix_cols  = ['State', 'County']\n",
    "    addtion_cols = ['log_Total_Whole', 'BlackWhiteRatio', 'Total_Black', 'org_Total_Whole']\n",
    "    addtion_cols = addtion_cols if 'IT_Disparity' in cols else addtion_cols + ['IT_Disparity']\n",
    "    \n",
    "    print('prefix cols:', prefix_cols)\n",
    "    print('addition cols:', addtion_cols)\n",
    "    \n",
    "    \n",
    "    # Step1: Slicing\n",
    "    newT = T2[prefix_cols + cols + addtion_cols]\n",
    "\n",
    "    # Step2: drop nan\n",
    "    \n",
    "    print('From:', newT.shape)#.head()\n",
    "    newT2 = newT.dropna()\n",
    "    print('Dropping Nan in Independent Variables')\n",
    "    print('To  :', newT2.shape)\n",
    "    # newT2\n",
    "    \n",
    "    # Step3: Dropping\n",
    "    # return newT2\n",
    "    # newT2 = newT2[newT2['org_Total_Whole'] >= 20000];print(newT2.shape)\n",
    "    # newT2 = newT2[newT2['Total_Black'] >= 400];print(newT2.shape)\n",
    "    newT2 = newT2[newT2['Total_Black'] >= 273];print(newT2.shape)\n",
    "    # newT2 = newT2[newT2['BlackWhiteRatio'] >= 0.01];print(newT2.shape)\n",
    "    # newT2 = newT2[newT2['CI_Disparity'] >= -0.05]; print(newT2.shape)\n",
    "    \n",
    "    \n",
    "    print('Dropping Small Black Population')\n",
    "    print('To  :', newT2.shape)\n",
    "    path2Dict = os.path.join(path, 'DataVarDict.csv')\n",
    "    path2Stata = os.path.join(path, 'Data.dta')\n",
    "    newT2.describe().T.to_csv(path2Dict)\n",
    "    newT2.to_stata(path2Stata)\n",
    "    print(path2Dict)\n",
    "    print(path2Stata)\n",
    "    \n",
    "    \n",
    "    # Step4: Normalizing, only cols\n",
    "    Y = cols[0]\n",
    "    if \"Y\" in Y:\n",
    "        not_normalized_cols = ['Vax_DisparityY','FluVax_DisparityY', 'republican', 'urban']\n",
    "    else:\n",
    "        not_normalized_cols = ['republican', 'urban']\n",
    "    \n",
    "    newT3 = newT2.copy()\n",
    "    for i in cols:\n",
    "        if i in not_normalized_cols:continue\n",
    "        df = newT3[i]\n",
    "        newT3[i]=(df-df.mean())/df.std()\n",
    "        \n",
    "    \n",
    "    path3Dict = os.path.join(path, 'DataVarDictNorm.csv')\n",
    "    newT3.describe().T.to_csv(path3Dict )\n",
    "    print(path3Dict)\n",
    "\n",
    "            \n",
    "    # Step5: Save Stata\n",
    "    path3Data = os.path.join(path, 'DataNorm.dta')\n",
    "    newT3.to_stata(path3Data)\n",
    "    print(path3Data)\n",
    "    \n",
    "    return newT2, newT3\n",
    "\n",
    "\n",
    "cols = ['Vax_Disparity', 'HighSchool_Disparity', 'HighSchool_Rate']\n",
    "newT2, newT3 = get_stata(T2, cols, path)\n",
    "# newT2 = newT2[newT2['CI_Disparity'] >= -0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-hungarian",
   "metadata": {},
   "source": [
    "# Stata Code\n",
    "\n",
    "## Get Regression Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "flush-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression(Y, X, CV, addText, state_dummy_num = '16'):\n",
    "    # Y: string\n",
    "    # X: list\n",
    "    # CV: dict(string: list)\n",
    "    \n",
    "    reg_string = ' '.join(['reg', Y] + X + sum([v for k, v in CV.items()], []))\n",
    "    # reg_string = reg_string+'dummy\n",
    "   \n",
    "    \n",
    "    reg_string = reg_string + ' state_dummy1-state_dummy{} '.format(state_dummy_num)\n",
    "    if addText.get('W'):\n",
    "        reg_string = reg_string + ' [pweight=org_Total_Whole] '  ### \n",
    "    if addText.get('R'):\n",
    "        reg_string = reg_string + ', r ' if ',' not in reg_string else reg_string + 'cluster(State) ' \n",
    "    if addText.get('C'):\n",
    "        reg_string = reg_string + ', cluster(State) ' if ',' not in reg_string else reg_string + 'cluster(State)'\n",
    "    # reg_string = reg_string + ', level()'\n",
    "    \n",
    "    return reg_string\n",
    "\n",
    "\n",
    "# addText = {\n",
    "#     'R': True,\n",
    "#     'C': True,\n",
    "#     'W': True\n",
    "# }\n",
    "\n",
    "\n",
    "# code = get_regression(Y, X, CV, addText, use_Age75 = False)\n",
    "# print(code)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-tractor",
   "metadata": {},
   "source": [
    "## Get Outreg2 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "taken-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outreg2(Y, X, DocName, addText, replace = False):\n",
    "    # Title = '_'.join(['Mdl', '.'.join([k for k, v in addText.items() if v] )])\n",
    "    # Title = Title[:-1] if Title[-1] == '_' else Title\n",
    "    # omit = \"state_dummy1-state_dummy\" + max_state + \" o.state_dummy1-o.state_dummy\" + max_state\n",
    "    Title = Y\n",
    "    TitleString = 'append ctitle({})'.format(Title) if not replace else 'replace ctitle({})'.format(Title)\n",
    "    addTextString = 'addtext(SD, True, ' + ', '.join([k + ', ' + str(v) for k, v in addText.items()]) + ')' \n",
    "    d = ' '.join(['outreg2 using', \n",
    "                  DocName + ',', \n",
    "                  TitleString,  \n",
    "                  addTextString, \n",
    "                  \" keep (\" +' '.join(X) + ') '\n",
    "                  'excel',\n",
    "                 # \"alpha(0.001, 0.01, 0.05)\"\n",
    "                 ])\n",
    "    return d\n",
    "    \n",
    "# DocName = 'Test.xlsx'\n",
    "# Title = 'First'\n",
    "# addText = {\n",
    "#     'R': True,\n",
    "#     'C': True,\n",
    "#     'W': True\n",
    "# }\n",
    "# replace = True\n",
    "\n",
    "# get_outreg2(Y, X, DocName, addText, replace, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cubic-expansion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/floydluo/Desktop/Covid19-Vaccination-Race-Disparity/StataReg/RegResult/2021-04-22_16-31-18/Data.dta'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataPath = os.path.join(os.getcwd(), path, 'Data.dta')\n",
    "DataPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-medicine",
   "metadata": {},
   "source": [
    " # Set Regression Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "posted-choir",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Vax_DisparityY', 'FluVax_DisparityY', 'MedianIncome', 'MedianIncome_Disparity', 'HighSchool_Rate', 'HighSchool_Disparity', 'FacNumRate', 'CaseRate', 'IT_Rate', 'IT_Disparity', 'urban', 'vehicle', 'republican_rate', 'Segregation', 'racial_weighted_bias', 'hesitancy', 'Black_Prop', 'FluVax_Rate', 'FluVax_Disparity', 'Above75_Rate', 'Above75_Disparity']\n",
      "prefix cols: ['State', 'County']\n",
      "addition cols: ['log_Total_Whole', 'BlackWhiteRatio', 'Total_Black', 'org_Total_Whole']\n",
      "From: (1199, 27)\n",
      "Dropping Nan in Independent Variables\n",
      "To  : (779, 27)\n",
      "(759, 27)\n",
      "Dropping Small Black Population\n",
      "To  : (759, 27)\n",
      "StataReg/RegResult/2021-04-22_16-31-18/DataVarDict.csv\n",
      "StataReg/RegResult/2021-04-22_16-31-18/Data.dta\n",
      "StataReg/RegResult/2021-04-22_16-31-18/DataVarDictNorm.csv\n",
      "StataReg/RegResult/2021-04-22_16-31-18/DataNorm.dta\n"
     ]
    }
   ],
   "source": [
    "Y  = 'Vax_DisparityY' \n",
    "Y2 = 'FluVax_DisparityY' \n",
    "X_list = [\n",
    "# Base Model\n",
    "[\n",
    "'MedianIncome', \n",
    "'MedianIncome_Disparity',\n",
    "\n",
    "'HighSchool_Rate',\n",
    "'HighSchool_Disparity',\n",
    "\n",
    "'FacNumRate', # 'logFacNum', # \n",
    "'CaseRate', #'logcases', \n",
    "\n",
    "'IT_Rate',\n",
    "'IT_Disparity',\n",
    "\n",
    "'urban',\n",
    "\n",
    "'vehicle',\n",
    "\n",
    "'republican_rate', # 'republican', #  'republican_07', #  'republican_03',\n",
    "\n",
    "'Segregation',\n",
    "\n",
    "'racial_weighted_bias',\n",
    "\n",
    "'hesitancy',\n",
    "\n",
    "\n",
    "'Black_Prop',\n",
    "\n",
    "],\n",
    "\n",
    "# Robustness Check \n",
    "[\n",
    "'FluVax_Rate',\n",
    "'FluVax_Disparity'\n",
    "],\n",
    "\n",
    "[\n",
    "'Above75_Rate',\n",
    "'Above75_Disparity'\n",
    "],\n",
    "]\n",
    "\n",
    "all_variables = [Y, Y2] + sum(X_list, [])\n",
    "print(all_variables)\n",
    "newT2, newT3 = get_stata(T2, all_variables, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "binary-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Robust Check: GSample\n",
    "\n",
    "# state_dummy_num = 16 \n",
    "# DocName = os.path.join(path, 'RegResultRobust.doc')\n",
    "# DataPath = os.path.join(os.getcwd(), path, 'DataNorm.dta')\n",
    "\n",
    "\n",
    "# L = [\n",
    "#     'clear all',\n",
    "#     'set more off',\n",
    "#     'use \"' + DataPath + '\"',\n",
    "#     '\\n', \n",
    "#     # \"preserve\\n\", \n",
    "#     \"tab State, generate(state_dummy)\",\n",
    "#     '\\n',  \n",
    "# ]\n",
    "\n",
    "# L = L  + ['winsor2 {}, replace cuts(5 95)'.format(i) for i in all_variables] + ['\\n\\n']\n",
    "\n",
    "\n",
    "# addText = {\n",
    "#     'R': True,\n",
    "#     'C': True,\n",
    "#     'W': True,\n",
    "# }\n",
    "# CV = {}\n",
    "\n",
    "# Title = 'FVAD' if 'flu' in Y.lower() else 'CVAD'\n",
    "\n",
    "# # Regression_Commands = []\n",
    "# idx = 0\n",
    "# X_used = sum(X_list[:idx+ 1], [])\n",
    "# reg_string = get_regression(Y, X_used, CV, addText, state_dummy_num)\n",
    "    \n",
    "# for idx in list(range(15)):\n",
    "    \n",
    "#     # Regression_Commands.append(reg_string) \n",
    "#     replace = True if idx == 0 else False\n",
    "#     out = get_outreg2(Title, X_used, DocName, addText, replace)\n",
    "#     L = L + ['preserve\\n', 'gsample 95, percent\\n',  reg_string+'\\n', out, '\\n', 'restore\\n\\n\\n']\n",
    "\n",
    "\n",
    "# stata_string =  '\\n'.join(L)\n",
    "# StataCodePath = os.path.join(os.getcwd(), path, 'do_file_robust.do')\n",
    "# print(StataCodePath, '\\n\\n\\n')\n",
    "# print(stata_string)\n",
    "# with open(StataCodePath, 'w') as f:\n",
    "#     f.write(stata_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inner-buddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/floydluo/Desktop/Covid19-Vaccination-Race-Disparity/StataReg/RegResult/2021-04-22_16-31-18/do_file.do \n",
      "\n",
      "\n",
      "\n",
      "clear all\n",
      "set more off\n",
      "use \"/Users/floydluo/Desktop/Covid19-Vaccination-Race-Disparity/StataReg/RegResult/2021-04-22_16-31-18/DataNorm.dta\"\n",
      "\n",
      "\n",
      "tab State, generate(state_dummy)\n",
      "\n",
      "\n",
      "winsor2 Vax_DisparityY, replace cuts(5 95)\n",
      "winsor2 FluVax_DisparityY, replace cuts(5 95)\n",
      "winsor2 MedianIncome, replace cuts(5 95)\n",
      "winsor2 MedianIncome_Disparity, replace cuts(5 95)\n",
      "winsor2 HighSchool_Rate, replace cuts(5 95)\n",
      "winsor2 HighSchool_Disparity, replace cuts(5 95)\n",
      "winsor2 FacNumRate, replace cuts(5 95)\n",
      "winsor2 CaseRate, replace cuts(5 95)\n",
      "winsor2 IT_Rate, replace cuts(5 95)\n",
      "winsor2 IT_Disparity, replace cuts(5 95)\n",
      "winsor2 urban, replace cuts(5 95)\n",
      "winsor2 vehicle, replace cuts(5 95)\n",
      "winsor2 republican_rate, replace cuts(5 95)\n",
      "winsor2 Segregation, replace cuts(5 95)\n",
      "winsor2 racial_weighted_bias, replace cuts(5 95)\n",
      "winsor2 hesitancy, replace cuts(5 95)\n",
      "winsor2 Black_Prop, replace cuts(5 95)\n",
      "winsor2 FluVax_Rate, replace cuts(5 95)\n",
      "winsor2 FluVax_Disparity, replace cuts(5 95)\n",
      "winsor2 Above75_Rate, replace cuts(5 95)\n",
      "winsor2 Above75_Disparity, replace cuts(5 95)\n",
      "\n",
      "\n",
      "\n",
      "reg Vax_DisparityY MedianIncome MedianIncome_Disparity HighSchool_Rate HighSchool_Disparity FacNumRate CaseRate IT_Rate IT_Disparity urban vehicle republican_rate Segregation racial_weighted_bias hesitancy Black_Prop state_dummy1-state_dummy16  [pweight=org_Total_Whole] , r cluster(State)\n",
      "\n",
      "outreg2 using StataReg/RegResult/2021-04-22_16-31-18/RegResult.doc, replace ctitle(CVAD) addtext(SD, True, R, True, C, True, W, True)  keep (MedianIncome MedianIncome_Disparity HighSchool_Rate HighSchool_Disparity FacNumRate CaseRate IT_Rate IT_Disparity urban vehicle republican_rate Segregation racial_weighted_bias hesitancy Black_Prop) excel\n",
      "\n",
      "\n",
      "reg FluVax_DisparityY MedianIncome MedianIncome_Disparity HighSchool_Rate HighSchool_Disparity FacNumRate CaseRate IT_Rate IT_Disparity urban vehicle republican_rate Segregation racial_weighted_bias hesitancy Black_Prop state_dummy1-state_dummy16  [pweight=org_Total_Whole] , r cluster(State)\n",
      "\n",
      "outreg2 using StataReg/RegResult/2021-04-22_16-31-18/RegResult.doc, append ctitle(FVAD) addtext(SD, True, R, True, C, True, W, True)  keep (MedianIncome MedianIncome_Disparity HighSchool_Rate HighSchool_Disparity FacNumRate CaseRate IT_Rate IT_Disparity urban vehicle republican_rate Segregation racial_weighted_bias hesitancy Black_Prop) excel\n",
      "\n",
      "\n",
      "reg Vax_DisparityY MedianIncome MedianIncome_Disparity HighSchool_Rate HighSchool_Disparity FacNumRate CaseRate IT_Rate IT_Disparity urban vehicle republican_rate Segregation racial_weighted_bias hesitancy Black_Prop FluVax_Rate FluVax_Disparity state_dummy1-state_dummy16  [pweight=org_Total_Whole] , r cluster(State)\n",
      "\n",
      "outreg2 using StataReg/RegResult/2021-04-22_16-31-18/RegResult.doc, append ctitle(CVAD) addtext(SD, True, R, True, C, True, W, True)  keep (MedianIncome MedianIncome_Disparity HighSchool_Rate HighSchool_Disparity FacNumRate CaseRate IT_Rate IT_Disparity urban vehicle republican_rate Segregation racial_weighted_bias hesitancy Black_Prop FluVax_Rate FluVax_Disparity) excel\n",
      "\n",
      "\n",
      "reg Vax_DisparityY MedianIncome MedianIncome_Disparity HighSchool_Rate HighSchool_Disparity FacNumRate CaseRate IT_Rate IT_Disparity urban vehicle republican_rate Segregation racial_weighted_bias hesitancy Black_Prop FluVax_Rate FluVax_Disparity Above75_Rate Above75_Disparity state_dummy1-state_dummy16  [pweight=org_Total_Whole] , r cluster(State)\n",
      "\n",
      "outreg2 using StataReg/RegResult/2021-04-22_16-31-18/RegResult.doc, append ctitle(CVAD) addtext(SD, True, R, True, C, True, W, True)  keep (MedianIncome MedianIncome_Disparity HighSchool_Rate HighSchool_Disparity FacNumRate CaseRate IT_Rate IT_Disparity urban vehicle republican_rate Segregation racial_weighted_bias hesitancy Black_Prop FluVax_Rate FluVax_Disparity Above75_Rate Above75_Disparity) excel\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state_dummy_num = 16 \n",
    "DocName = os.path.join(path, 'RegResult.doc')\n",
    "\n",
    "\n",
    "# Normalized\n",
    "DataPath = os.path.join(os.getcwd(), path, 'DataNorm.dta')\n",
    "\n",
    "# Original One\n",
    "# DataPath = os.path.join(os.getcwd(), path, 'Data.dta')\n",
    "\n",
    "\n",
    "L = [\n",
    "    # 'ssc install grstyle', \n",
    "    # 'ssc install coefplot', \n",
    "    # 'ssc install palettes',\n",
    "    # 'ssc install colrspace',\n",
    "    'clear all',\n",
    "    'set more off',\n",
    "    'use \"' + DataPath + '\"',\n",
    "    '\\n', \n",
    "    # \"preserve\\n\", \n",
    "    \"tab State, generate(state_dummy)\",\n",
    "    '\\n',  \n",
    "]\n",
    "\n",
    "# \n",
    "# L = L  + ['winsor2 {}, replace cuts(1 99)'.format(i) for i in all_variables] + ['\\n\\n']\n",
    "# L = L  + ['winsor2 {}, replace cuts(2 98)'.format(i) for i in all_variables] + ['\\n\\n']\n",
    "L = L  + ['winsor2 {}, replace cuts(5 95)'.format(i) for i in all_variables] + ['\\n\\n']\n",
    "# L = L  + ['winsor2 {}, replace cuts(10 90)'.format(i) for i in all_variables] + ['\\n\\n']\n",
    "\n",
    "\n",
    "addText = {\n",
    "    'R': True,\n",
    "    'C': True,\n",
    "    'W': True,\n",
    "}\n",
    "CV = {}\n",
    "\n",
    "Title = 'FVAD' if 'flu' in Y.lower() else 'CVAD'\n",
    "\n",
    "Regression_Commands = []\n",
    "\n",
    "\n",
    "for idx, X in enumerate(X_list):\n",
    "    X_used = sum(X_list[:idx+ 1], [])\n",
    "    reg_string = get_regression(Y, X_used, CV, addText, state_dummy_num)\n",
    "    \n",
    "    Regression_Commands.append(reg_string) \n",
    "    \n",
    "    \n",
    "    replace = True if idx == 0 else False\n",
    "    out = get_outreg2(Title, X_used, DocName, addText, replace)\n",
    "\n",
    "    L = L +[reg_string+'\\n', out, '\\n']\n",
    "    if X_used[-1] == 'Black_Prop':\n",
    "        reg_string = get_regression(Y2, X_used, CV, addText, state_dummy_num)\n",
    "        replace = True if idx == 0 else False\n",
    "        out = get_outreg2('FVAD', X_used, DocName, addText, False)\n",
    "        L = L +[reg_string+'\\n', out, '\\n']\n",
    "        \n",
    "        Regression_Commands.append(reg_string) \n",
    "\n",
    "\n",
    "visualization = [\n",
    "                 # Regression_Commands[0], 'estimates store covid', \n",
    "                 # Regression_Commands[1], 'estimates store flu', \n",
    "                 # 'grstyle init',\n",
    "                 # 'grstyle set plain, horizontal grid',\n",
    "                 # 'grstyle set color Accent: p#bar p#barline', \n",
    "                 # 'coefplot covid, bylabel(COVID19 Vaccination Disparity) || flu, bylabel(Flu Vaccination Disparity) ||, '\n",
    "                 # 'keep(MedianIncome MedianIncome_Diff HighSchool_Whole HighSchool_Diff logFacNum logcases CI_Whole CI_Diff urban vehicle republican Segregation racial_weighted_bias hesitancy ) '\n",
    "                 # 'xline(0) recast(bar) ciopts(recast(rcap)) citop barwidt(0.3) bgcolor(white) levels(95) '\n",
    "                 # 'rename(MedianIncome=\"Median Income\" MedianIncome_Diff = \"Median Income Disparity\" HighSchool_Whole=\"High School Graduation Rate\" HighSchool_Diff=\"High School Disparity\"  logFacNum=\"No. of Health Facilities\" logcases=\"No. of COVID-19 Cases\" CI_Whole=\"Home IT Rate\"  CI_Diff=\"Home IT Disparity\" urban=\"Urban\" vehicle=\"Rate of Vehicle Ownership\" republican=\"Political Ideology\" Segregation=\"Segregation Index\" racial_weighted_bias=\"Racial Bias\" hesitancy=\"Vaccine Hesitancy\") '\n",
    "                 # 'note(\"The x-axis is percentage point.\")'\n",
    "                ]\n",
    "\n",
    "L = L + visualization\n",
    "\n",
    "stata_string =  '\\n'.join(L)\n",
    "StataCodePath = os.path.join(os.getcwd(), path, 'do_file.do')\n",
    "print(StataCodePath, '\\n\\n\\n')\n",
    "print(stata_string)\n",
    "with open(StataCodePath, 'w') as f:\n",
    "    f.write(stata_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "atmospheric-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrgDF = T2.loc[newT2.index]# .to_stata('758ForRegression.dta')\n",
    "# # OrgDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "recorded-embassy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df = newT3[['Vax_DisparityY', 'FluVax_DisparityY',\n",
    "# #        'MedianIncome', 'MedianIncome_Disparity', 'HighSchool_Rate',\n",
    "# #        'HighSchool_Disparity', 'logFacNum', 'logcases', 'IT_Rate',\n",
    "# #        'IT_Disparity', 'urban', 'vehicle', 'republican_rate', 'Segregation',\n",
    "# #        'racial_weighted_bias', 'hesitancy', 'Black_Prop',]]# .corr().to_csv('Correlation_Matrix.csv')\n",
    "\n",
    "# df = newT3[['Vax_DisparityY', 'FluVax_DisparityY',\n",
    "#        'MedianIncome', 'MedianIncome_Disparity', 'HighSchool_Rate',\n",
    "#        'HighSchool_Disparity', 'FacNumRate', 'CaseRate', 'IT_Rate',\n",
    "#        'IT_Disparity', 'urban', 'vehicle', 'republican_rate', 'Segregation',\n",
    "#        'racial_weighted_bias', 'hesitancy', 'Black_Prop',]]\n",
    "\n",
    "\n",
    "# df = OrgDF[[ 'republican_rate', 'republican', 'FacNumRate', 'CaseRate', 'logFacNum', 'logcases','FacNum', 'cases',]]\n",
    "\n",
    "\n",
    "\n",
    "# from scipy.stats import pearsonr\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# rho = df.corr()\n",
    "# pval = df.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "# p = pval.applymap(lambda x: ''.join(['*' for t in [0.01,0.05,0.1] if x<=t]))\n",
    "# result = rho.round(2).astype(str) + p\n",
    "\n",
    "# result# .to_csv('Corr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-seventh",
   "metadata": {},
   "source": [
    "# Run Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "## Do some processing in Python\n",
    "\n",
    "## Set do-file information\n",
    "dofile = StataCodePath\n",
    "\n",
    "stata_app_path = '/Applications/Stata/StataSE.app/Contents/MacOS/StataSE'\n",
    "cmd = [stata_app_path, \"do\", dofile, \"mpg\", \"weight\", \"foreign\"]\n",
    "\n",
    "## Run do-file\n",
    "subprocess.call(cmd) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-suspect",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-bulgaria",
   "metadata": {},
   "source": [
    "## All Counties\n",
    "\n",
    "\n",
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 759\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# T2 = pd.read_csv('StataReg/CountyVaccineMarch27.csv')\n",
    "T2 = pd.read_csv('StataReg/CountyVaccineApril07.csv')\n",
    "print(T2.shape)\n",
    "# T2 = pd.read_csv('StataReg/CountyVaccineApril19.csv')\n",
    "# first processing\n",
    "T2 = T2[-T2['Vax_Disparity'].isna()]\n",
    "\n",
    "print(T2.shape)\n",
    "T2 = T2[T2['Vax_White'] < 1]\n",
    "T2 = T2[T2['Vax_Black'] < 1]\n",
    "print(T2.shape)\n",
    "# print(T2.shape)\n",
    "\n",
    "T2\n",
    "\n",
    "\n",
    "\n",
    "# RawData.loc[newT2.index][['Vax_White', 'Vax_Black', 'Vax_Disparity', 'FluVax_White', 'FluVax_Black', 'FluVax_Disparity',]].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Rate = T2[['Rate_Diff', 'Rate_Black', 'Rate_White',  'FluDiff', 'FluBlack', 'FluWhite',]].mean()*100\n",
    "# Rate\n",
    "\n",
    "\n",
    "RawData = T2\n",
    "print(RawData.shape)\n",
    "\n",
    "\n",
    "L = []\n",
    "\n",
    "for idx, row in RawData.iterrows():\n",
    "    d = row.to_dict()\n",
    "    dn = {}\n",
    "    dn['Vaccination'] = 'COVID-19'\n",
    "    dn['Race'] = 'Black'\n",
    "    dn['Rate (%)'] = d['Vax_Black'] * 100\n",
    "    L.append(dn)\n",
    "                    \n",
    "                    \n",
    "    dn = {}\n",
    "    dn['Vaccination'] = 'COVID-19'\n",
    "    dn['Race'] = 'White'\n",
    "    dn['Rate (%)'] = d['Vax_White']* 100\n",
    "    L.append(dn)\n",
    "                    \n",
    "                    \n",
    "    dn = {}\n",
    "    dn['Vaccination'] = 'Flu'\n",
    "    dn['Race'] = 'Black'\n",
    "    dn['Rate (%)'] = d['FluVax_Black']* 100\n",
    "    L.append(dn)\n",
    "    \n",
    "    dn = {}\n",
    "    dn['Vaccination'] = 'Flu'\n",
    "    dn['Race'] = 'White'\n",
    "    dn['Rate (%)'] = d['FluVax_White']* 100\n",
    "    L.append(dn)\n",
    "    \n",
    "newdf = pd.DataFrame(L)\n",
    "\n",
    "# newdf\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "val = 1.6\n",
    "\n",
    "sns.set(font_scale=val)\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn\n",
    "\n",
    "# import mylib\n",
    "\n",
    "dims = (8, 6)\n",
    "# df = mylib.load_data()\n",
    "fig, ax = pyplot.subplots(figsize=dims)\n",
    "# seaborn.violinplot(ax=ax, data=df, **violin_options)\n",
    "\n",
    "\n",
    "# df.to_csv('759_rate.csv')\n",
    "ax = sns.barplot(x=\"Vaccination\" , y=\"Rate (%)\", hue=\"Race\", palette = ['grey', 'red'], alpha = 0.5,\n",
    "                 data=newdf,errwidth = 1, errcolor = 'black', capsize=.3).set_title('Vaccination Rate (1192 Counties) on April 07')\n",
    "# ax.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('April 07')\n",
    "Rate = RawData[['Vax_Disparity', 'Vax_Black', 'Vax_White',  'FluVax_Disparity', 'FluVax_Black', 'FluVax_White',]].mean()*100\n",
    "Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-choir",
   "metadata": {},
   "source": [
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Rate = T2[['Rate_Diff', 'Rate_Black', 'Rate_White',  'FluDiff', 'FluBlack', 'FluWhite',]].mean()*100\n",
    "# Rate\n",
    "\n",
    "RawData = T2\n",
    "print(RawData.shape)\n",
    "\n",
    "\n",
    "dims = (8, 6)\n",
    "# df = mylib.load_data()\n",
    "fig, ax = pyplot.subplots(figsize=dims)\n",
    "\n",
    "ax = sns.distplot(RawData['Vax_Black']*100, hist=True, kde=True, \n",
    "            bins=int(300), color = 'grey',\n",
    "            kde_kws={'linewidth': 1}, label='Black')\n",
    "\n",
    "ax = sns.distplot(RawData['Vax_White']*100, hist=True, kde=True,\n",
    "            bins=int(100), color = 'red',\n",
    "            kde_kws={'linewidth': 1}, label='White')\n",
    "\n",
    "pyplot.legend(loc='best')\n",
    "\n",
    "\n",
    "ax.set(xlabel='COVID-19 Vaccination Rate (%) Distribution On April 19')\n",
    "ax.set(ylabel ='Density')\n",
    "ax.set(xlim=(0, 100))\n",
    "ax.set(ylim=(0, 0.11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = (8, 6)\n",
    "# df = mylib.load_data()\n",
    "fig, ax = pyplot.subplots(figsize=dims)\n",
    "\n",
    "\n",
    "# sns.set_style(\"whitegrid\")\n",
    "ax = sns.distplot(RawData['FluVax_White'] * 100, hist=True, kde=True,\n",
    "            bins=int(100), color = 'red',\n",
    "            kde_kws={'linewidth': 1}, label='White')\n",
    "ax = sns.distplot(RawData['FluVax_Black'] * 100, hist=True, kde=True,\n",
    "            bins=int(100), color = 'grey',\n",
    "            kde_kws={'linewidth': 1}, label='Black')\n",
    "pyplot.legend(loc='best')\n",
    "ax.set(xlabel='Flu Vaccination Rate (%) Distribution In 2019')\n",
    "ax.set(ylabel='Density')\n",
    "ax.set(xlim=(0, 100))\n",
    "ax.set(ylim=(0, 0.11))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-renaissance",
   "metadata": {},
   "source": [
    "## 759 Counties\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-dream",
   "metadata": {},
   "source": [
    "### Scatter Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "cols = ['Vax_DisparityY', 'FluVax_DisparityY', 'MedianIncome_Disparity',  'HighSchool_Disparity', \n",
    "         'logcases', 'logFacNum', 'IT_Rate',\n",
    "        'republican','Segregation',  'vehicle',   ]\n",
    "\n",
    "print(cols)\n",
    "\n",
    "df = newT2[cols]\n",
    "\n",
    "new_cols = ['CVD (%)', 'FVD (%)', 'Income Disparity',  'High School Disparity',\n",
    "          'Covid Cases', 'Health Facility Num',  'Home IT Rate', \n",
    "         'Political Ideology', 'Segregation', 'Vehicle Rate', ]\n",
    "df.columns = new_cols\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# winsorize 95\n",
    "val = 1.6\n",
    "\n",
    "sns.set(font_scale=val)\n",
    "\n",
    "sns.pairplot(df, \n",
    "             kind = 'reg', \n",
    "             plot_kws= {\n",
    "                 'line_kws':{'color':'orange'},\n",
    "             })\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
